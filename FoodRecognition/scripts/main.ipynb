{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the libraries\n",
    "import os, shutil\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initiate our environment variables\n",
    "# Directory where you'll store your dataset\n",
    "base_dir = '../src/food-101/'\n",
    "categories = ['sashimi', 'spaghetti_bol']\n",
    "dataset_steps = ['train', 'validation', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We call the classes\n",
    "do = DataOrganizer(base_dir=base_dir,\n",
    "                  category_list=categories,\n",
    "                  type_dir_list=dataset_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for the training, validation, and test splits\n",
    "train_dir, validation_dir, test_dir = do.creating_step_directories()\n",
    "type_dirs = [train_dir, validation_dir, test_dir]\n",
    "do.creating_dataset_directories()\n",
    "\n",
    "sashimi_names_list, spaghetti_bol_list = do.selecting_data_names()\n",
    "names_lists = [sashimi_names_list, spaghetti_bol_list]\n",
    "do.creating_datasets(names_lists=names_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataPreparator(rescale=1./255,\n",
    "                    type_dir_list=type_dirs,\n",
    "                    target_size=(150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen, validation_datagen, test_datagen = dp.image_rescaler()\n",
    "data_generators = [train_datagen, validation_datagen, test_datagen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1400 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, test_generator = dp.type_generator(data_generators=data_generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Building the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features extractor\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                       input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=70,\n",
    "                epochs=30,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/conv_net_20201228_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('../models/conv_net_20201228_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sashimi_sample = sashimi_train_names[0]\n",
    "spaghetti_bol_sample = spaghetti_bol_train_names[0]\n",
    "img_sashimi = image.load_img(sashimi_sample, target_size=(150, 150))\n",
    "print(type(img_sashimi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sashimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sashimi = image.img_to_array(img_sashimi)\n",
    "x_sashimi = x_sashimi.reshape((1,) + x_sashimi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x_sashimi, batch_size=1):\n",
    "    plt.figure()\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i = i + 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features extractor\n",
    "model_drop = models.Sequential()\n",
    "model_drop.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                       input_shape=(150, 150, 3)))\n",
    "model_drop.add(layers.MaxPooling2D((2, 2)))\n",
    "model_drop.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_drop.add(layers.MaxPooling2D((2, 2)))\n",
    "model_drop.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_drop.add(layers.MaxPooling2D((2, 2)))\n",
    "model_drop.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model_drop.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier with dropout\n",
    "model_drop.add(layers.Flatten())\n",
    "model_drop.add(layers.Dropout(0.2))\n",
    "model_drop.add(layers.Dense(512, activation='relu'))\n",
    "model_drop.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model_drop using data augmentation\n",
    "train_datagen_drop = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "test_datagen_drop = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_drop = train_datagen_drop.flow_from_directory(\n",
    "                                            train_dir,\n",
    "                                            target_size=(150, 150),\n",
    "                                            batch_size=20,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "validation_generator_drop = test_datagen_drop.flow_from_directory(\n",
    "                                            validation_dir,\n",
    "                                            target_size=(150, 150),\n",
    "                                            batch_size=20,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_drop = model_drop.fit_generator(\n",
    "                            train_generator_drop,\n",
    "                            steps_per_epoch=70,\n",
    "                            epochs=40,\n",
    "                            validation_data=validation_generator_drop,\n",
    "                            validation_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_performanceperformance(history_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop.save('../models/conv_net_20201229_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction without data augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features, validation_labels = extract_features(validation_dir, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = extract_features(test_dir, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (1400, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (300, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (300, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = models.Sequential()\n",
    "model_conv.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model_conv.add(layers.Dropout(0.2))\n",
    "model_conv.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv = model_conv.fit(train_features, train_labels,\n",
    "                             epochs=40,\n",
    "                             batch_size=20,\n",
    "                             validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_performance(history_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.save('../models/conv_net_20201229_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pre-trained net with data augmentation\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(150, 150, 3))\n",
    "\n",
    "model_conv_aug = models.Sequential()\n",
    "model_conv_aug.add(conv_base)\n",
    "model_conv_aug.add(layers.Flatten())\n",
    "model_conv_aug.add(layers.Dense(256, activation='relu'))\n",
    "model_conv_aug.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(len(model_conv_aug.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print(len(model_conv_aug.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model_drop using data augmentation\n",
    "train_datagen_conv_aug = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "test_datagen_conv_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator_conv_aug = train_datagen_conv_aug.flow_from_directory(\n",
    "                                            train_dir,\n",
    "                                            target_size=(150, 150),\n",
    "                                            batch_size=20,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "validation_generator_conv_aug = test_datagen_conv_aug.flow_from_directory(\n",
    "                                            validation_dir,\n",
    "                                            target_size=(150, 150),\n",
    "                                            batch_size=20,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_aug.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_aug = model_conv_aug.fit_generator(\n",
    "                            train_generator_conv_aug,\n",
    "                            steps_per_epoch=70,\n",
    "                            epochs=3,\n",
    "                            validation_data=validation_generator_conv_aug,\n",
    "                            validation_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_aug.save('../models/conv_net_20201230_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine Tuning\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuning = keras.models.load_model('../models/conv_net_20201230_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuning.compile(loss='binary_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "                    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tuning = model_tuning.fit_generator(train_generator_conv_aug,\n",
    "                                           steps_per_epoch=70,\n",
    "                                           epochs=3,\n",
    "                                           validation_data=validation_generator_conv_aug,\n",
    "                                           validation_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_performance(history_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuning.save('../models/conv_net_20201230_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_performance_smoothed(history_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen_conv_aug.flow_from_directory(\n",
    "                                test_dir,\n",
    "                                target_size=(150, 150),\n",
    "                                batch_size=20,\n",
    "                                class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model_tuning.evaluate_generator(test_generator, steps=15)\n",
    "print('test_acc', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing intermediate activations\n",
    "model_vis = keras.models.load_model('../models/conv_net_20201229_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../src/food-101/test/sashimi/1039599.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "print(img_tensor.shape)\n",
    "\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255. # the model was trained on inputs that were preprocessed this way\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model_vis.layers[:8]]\n",
    "activation_model = models.Model(inputs=model_vis.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img_tensor)\n",
    "print(len(activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in activations:\n",
    "    plt.matshow(i[0, :, :, 8], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing every channel in every intermediate activation\n",
    "layer_names = []\n",
    "for layer in model_vis.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    \n",
    "    size = layer_activation.shape[1] # the feature map has shape (l, size, size, n_features)\n",
    "    \n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        \n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "        \n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, \n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "        \n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing convnet filters\n",
    "# defining the loss tensor for filter visualization\n",
    "\n",
    "model_filters = VGG16(weights='imagenet',\n",
    "                     include_top=False)\n",
    "\n",
    "layer_name = 'block3_conv1'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = model_filters.get_layer(layer_name).output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the gradient of the loss with regard to the input\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "grads = K.gradients(loss, model_filters.input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Numpy output values given Numpy input values\n",
    "iterate = K.function([model_filters.input], [loss, grads])\n",
    "\n",
    "loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss maximation via stochastic gradient descent\n",
    "input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128\n",
    "\n",
    "step = 1.\n",
    "for i in range(40):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += grads_value * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generate_pattern('block3_conv1', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a grid of all filter response patterns in a layer\n",
    "layer_name = 'block1_conv1'\n",
    "size = 64\n",
    "margin = 5\n",
    "\n",
    "results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3))\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
    "        \n",
    "        horizontal_start = i * size + i * margin\n",
    "        horizontal_end = horizontal_start + size\n",
    "        vertical_start = j * size + j * margin\n",
    "        vertical_end = vertical_start + size\n",
    "        results[horizontal_start: horizontal_end,\n",
    "                vertical_start: vertical_end, :] = filter_img\n",
    "results = results.astype(int)\n",
    "        \n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing heatmaps of class activation\n",
    "# cam visualization\n",
    "model_cam = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../src/food-101/test/spaghetti_bol/1915989.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_cam.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaghetti_output = model_cam.output[:, 959]\n",
    "last_conv_layer = model_cam.get_layer('block5_conv3')\n",
    "\n",
    "grads = K.gradients(spaghetti_output, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "iterate = K.function([model_cam.input],\n",
    "                    [pooled_grads, last_conv_layer.output[0]])\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.figure(figsize=(50, 50))\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('../src/food-101/test/superimposed.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
