{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis Hotel Booking Demand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_functions import *\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('hotel_bookings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_csv(df_original)\n",
    "count_nulls(df_original)\n",
    "hist_boxplot(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119390, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows and columns\n",
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(column):\n",
    "    upper = column.max()\n",
    "    lower = column.min()\n",
    "    y = (column - lower)/(upper-lower)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - First Remarks and ideas for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style='color:Orange'> **hotel** </span>: 2 classes, 66% City Hotel, 33% Resort Hotel\n",
    "- <span style='color:Orange'> **is_canceled** </span> (target_label): 2 values, 0 (62%) or 1 (38%). It is quite unbalanced\n",
    "- <span style='color:Orange'> **lead_time** </span>: many values, grouping by new categories? Skewed distributions towards the 0 value\n",
    "- <span style='color:Orange'> **arrival_date_year** </span>: 3 years, 2015, 2016 and 2017\n",
    "- <span style='color:Orange'> **arrival_date_month** </span>: many arrivals in June and July, it makes sense\n",
    "- <span style='color:Orange'> **arrival_date_week_number** </span>: probably we can combine it with arrival_date_month. It has a quite normal distribution\n",
    "- <span style='color:Orange'> **arrival_date_day_of_month** </span>: considering we have week_number and month_number we can eliminate this label\n",
    "- <span style='color:Orange'> **stays_in_weekend_nights** </span>: skewed distribution towards 0, we could eliminate some big values\n",
    "- <span style='color:Orange'> **stays_in_week_nights** </span>: same thought of previous label\n",
    "- <span style='color:Orange'> **adults** </span>: 2 is 75% and 1 is 19%, there are some values with 0\n",
    "- <span style='color:Orange'> **children** </span>: 93% has 0 children, we can think of eliminate this label or consider to create only a binary class, 4 <span style='color:Yellow'> **null** </span> values\n",
    "- <span style='color:Orange'> **babies** </span>: 99% has 0 babies, same thought of children\n",
    "- <span style='color:Orange'> **meal** </span>: 3 relevant classes, BB 77%, HB 12% and SC 8%\n",
    "- <span style='color:Orange'> **country** </span>: 6 relevant classes, PRT 41%, GBR 10%, FRA 9%, ESP 7%, DEU 6%, ITA 3%, 0.4% of <span style='color:Yellow'> **null** </span> values\n",
    "- <span style='color:Orange'> **market_segment** </span>: 5 relevant classes, Online TA 47%, Offline TA/TO 20%, Groups 17%, Direct 10% and Corporate 4.4%\n",
    "- <span style='color:Orange'> **distribution_channel** </span>: 3 relevant classes TA/TO 82%, Direct 12% and Corporate 5%\n",
    "- <span style='color:Orange'> **is_repeated_guest** </span>: the clients are quite new, 0 is 97% and 1 is 3%\n",
    "- <span style='color:Orange'> **previous_cancellations** </span>: two relevant classes, 0 is about 95% and 1 is about 5%. We could transform this into a binary label\n",
    "- <span style='color:Orange'> **previous_bookings_not_canceled** </span>: it is not relevant since we have previous cancellations.\n",
    "- <span style='color:Orange'> **reserved_room_type** </span>: 4 relevant classes, A is 72%, D is 16%, E is 5%, F is 2.4 %\n",
    "- <span style='color:Orange'> **assigned_room_type** </span>: 3 relevant classes, A is 62%, B 21% and E 6%. It could be interesting to know when the customer knows the **assigned_room_type**. If they knew this online some time before, it could be a reason for cancellation\n",
    "- <span style='color:Orange'> **booking_changes** </span>: distribution is skewed towards 0, 3 relevant classes, 0 is 85%, 1 is 10% and 2 is 3%. More changes imply a high probable cancellation?\n",
    "- <span style='color:Orange'> **deposit_type** </span>: only 3 classes, No deposit 87%, Non Refund 12% and Refundable 1%. We could Merge Refundable with No deposit? Non refund implies no cancellation?\n",
    "- <span style='color:Orange'> **agent** </span>: too many values, it seems to be without important information, 13% <span style='color:Yellow'> **nulls** </span>. We can cancel this label\n",
    "- <span style='color:Orange'> **company** </span>: 94% of rows are <span style='color:Yellow'> **null** </span>\n",
    "- <span style='color:Orange'> **days_in_waiting_list** </span>: there are many values but 97% of rows is 0. Binary label?\n",
    "- <span style='color:Orange'> **customer_type** </span>: only 4 classes, Transient is 75%, Transient-Party 21%, Contract is about 3.5% and Group is about 0.5%\n",
    "- <span style='color:Orange'> **adr** </span>: there are some annoying outliers, we need to group the values somehow\n",
    "- <span style='color:Orange'> **required_car_parking_spaces** </span>: only two relevant classes, 0 is about 94% and 1 is about 6%. Trasnform it in a binary label\n",
    "- <span style='color:Orange'> **total_of_special_requests** </span>: only 3 relevant classes, 0 is 59%, 1 is 28% and 2 is 10%. Maybe we could group the information\n",
    "- <span style='color:Orange'> **reservation_status** </span>: this is a posteriori information, we should eliminate it\n",
    "- <span style='color:Orange'> **reservation_status_date** </span>: non-important information, eliminate this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Grouping, Treating outliers and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.copy()\n",
    "\n",
    "# lead_time column\n",
    "df['lead_time'] = np.where(df['lead_time']>365, 365, df['lead_time'])\n",
    "\n",
    "# arrival_date_month\n",
    "df.drop('arrival_date_month', axis = 1, inplace = True)\n",
    "\n",
    "# arrival_date_week_number\n",
    "# Grouping considering first half of the month and second half\n",
    "df['arrival_date_week_number'] = (df['arrival_date_week_number']-1) // 2\n",
    "\n",
    "# arrival_date_day_of_month\n",
    "df.drop('arrival_date_day_of_month', axis = 1, inplace = True)\n",
    "\n",
    "# stays_in_weekend_nights\n",
    "df['stays_in_weekend_nights'] = np.where(df['stays_in_weekend_nights']>2, 3, df['stays_in_weekend_nights'])\n",
    "\n",
    "# stays_in_week_nights\n",
    "df['stays_in_week_nights'] = np.where(df['stays_in_week_nights']>5, 6, df['stays_in_week_nights'])\n",
    "\n",
    "# adults\n",
    "df['adults'] = np.where(df['adults']>3, 3, df['adults'])\n",
    "df['adults'].replace(0, df['adults'].median(), inplace = True)\n",
    "\n",
    "# children\n",
    "df['children'] = np.where(df['children']>0, 1, df['children'])\n",
    "df['children'].replace(np.nan, 0, inplace = True)\n",
    "\n",
    "# babies\n",
    "df.drop('babies', axis = 1, inplace = True)\n",
    "\n",
    "# meal\n",
    "# We merge Undefined with SC (no service)\n",
    "# and full breakfast with half breakfast\n",
    "df['meal'].replace({'Undefined': 'SC', 'FB':'HB'}, inplace = True)\n",
    "\n",
    "# country\n",
    "countries = pd.read_csv('value_counts_csv/country.csv')\n",
    "top_country = list(countries['country'].head(6))\n",
    "df['country'] = np.where(df['country'].isin(top_country), df['country'], 'Others')\n",
    "\n",
    "# market_segment and distribution_channel\n",
    "# Further EDA for studying the relation between \n",
    "# market_segment and distribution_channel, they seem similar\n",
    "df.groupby(['market_segment', 'distribution_channel']).size().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style='color:Orange'> **Market segment** </span> seems to be a specialization of <span style='color:Orange'> **distribution channel** </span>. We decide to keep the former and drop the latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('distribution_channel', axis = 1, inplace = True)\n",
    "\n",
    "market_segments = pd.read_csv('value_counts_csv/market_segment.csv')\n",
    "top_segments = list(market_segments['market_segment'].head(4))\n",
    "df['market_segment'] = np.where(df['market_segment'].isin(top_segments), df['market_segment'], 'Others')\n",
    "\n",
    "# previous_cancellations\n",
    "df['previous_cancellations'] = np.where(df['previous_cancellations']>1, 1, 0)\n",
    "\n",
    "# previous_bookings_not_canceled\n",
    "df.drop('previous_bookings_not_canceled', axis = 1, inplace = True)\n",
    "\n",
    "# reserved_room_type\n",
    "room_types = pd.read_csv('value_counts_csv/reserved_room_type.csv')\n",
    "top_room = list(room_types['reserved_room_type'].head(4))\n",
    "df['reserved_room_type'] = np.where(df['reserved_room_type'].isin(top_segments), df['market_segment'], 'Others')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We interpret the assigned_room_type label as assigned a posteriori. Therefore we decide to drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigned_room_type\n",
    "df.drop('assigned_room_type', axis = 1, inplace = True)\n",
    "\n",
    "# booking_changes\n",
    "df['booking_changes'] = np.where(df['booking_changes']>2, 2, df['booking_changes'])\n",
    "\n",
    "# deposit_type\n",
    "df['deposit_type'].replace('Refundable', 'No Deposit', inplace = True)\n",
    "\n",
    "# agent\n",
    "df.drop('agent', axis = 1, inplace = True)\n",
    "\n",
    "# company\n",
    "df.drop('company', axis = 1, inplace = True)\n",
    "\n",
    "# days_in_waiting_list\n",
    "df['days_in_waiting_list'] = np.where(df['days_in_waiting_list']>0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are confused about the interpretation of the <font color='orange'>**adr**</font> label and we decide not to consider it. We are not sure if it includes some a posteriori information. We can come back to it in further phase if some new interpreation arises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required_car_parking_spaces\n",
    "df['required_car_parking_spaces'] = np.where(df['required_car_parking_spaces']>0, 1, 0)\n",
    "\n",
    "# total_of_special_requests\n",
    "df['total_of_special_requests'] = np.where(df['total_of_special_requests']>1, 2, df['total_of_special_requests'])\n",
    "\n",
    "# reservation_status and reservation_status_date\n",
    "df.drop(['reservation_status', 'reservation_status_date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python setup.py install--user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()\n",
    "df_model = df_model.select_dtypes(exclude=['object'])\n",
    "df_model = pd.get_dummies(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.shape\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop('is_canceled', axis = 1)\n",
    "y = df_model['is_canceled']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=Y_test)\n",
    "\n",
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 2} \n",
    "\n",
    "steps = 20  # The number of training iterations\n",
    "\n",
    "model = xgb.train(param, D_train, steps)\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "print(preds)\n",
    "\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print(best_preds)\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "     \"eta\"    : [0.20, 0.30] ,\n",
    "     \"max_depth\"        : [ 3, 6],\n",
    "     \"gamma\"            : [ 0.1, 0.2]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(xgb_clf,\n",
    "                    parameters,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "model = grid.fit(X_train, Y_train)\n",
    "#predictions = model.predict(X_test)\n",
    "\n",
    "#model.dump_model('dump.raw.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_\n",
    "model.best_estimator_\n",
    "cvres = model.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(train['QuoteConversion_Flag'], n_folds=5, shuffle=True), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clf.fit(train[features], train[\"QuoteConversion_Flag\"])\n",
    "\n",
    "#trust your CV!\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "test_probs = clf.predict_proba(test[features])[:,1]\n",
    "\n",
    "sample = pd.read_csv('../input/sample_submission.csv')\n",
    "sample.QuoteConversion_Flag = test_probs\n",
    "sample.to_csv(\"xgboost_best_parameter_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_gridCV(X_train, y_train, clf, \n",
    "                      X_test = None, y_test = None, cv = 3, scoring = 'accuracy', params = {}, model_name = \"model\"):\n",
    "    \n",
    "    grid = GridSearchCV(clf, params, cv = cv, scoring = scoring, refit = True)\n",
    "    \n",
    "    model = grid.fit(X_train, y_train)\n",
    "    print(\"The best parameters of grid are: \", model.best_params_, \n",
    "          \"\\nThe best estimator is: \", model.best_estimator_)\n",
    "    \n",
    "    if not os.path.exists('Models/CV_results'):\n",
    "        os.makedirs('Models/CV_results')\n",
    "    \n",
    "    cvres = model.cv_results_\n",
    "    \n",
    "    if params != {}:    \n",
    "        dataframe = pd.DataFrame(cvres[\"params\"])\n",
    "        dataframe.insert(0, \"mean_test_score\", cvres[\"mean_test_score\"])\n",
    "                        \n",
    "    else: \n",
    "        dataframe = pd.DataFrame({\"mean_test_score\":cvres[\"mean_test_score\"]})\n",
    "            \n",
    "    dataframe.to_csv(\"./Models/CV_results/CV_results_\"+model_name+\".csv\", index = False) \n",
    "    \n",
    "    if X_test is not None:\n",
    "        results = model.predict(X_test)\n",
    "    \n",
    "        if y_test is not None:\n",
    "            print(\"Precision = {}\".format(precision_score(y_test, results, average='macro')))\n",
    "            print(\"Recall = {}\".format(recall_score(y_test, results, average='macro')))\n",
    "            print(\"Accuracy = {}\".format(accuracy_score(y_test, results)))\n",
    "            \n",
    "    return(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gridCV(X_train, Y_train, xgb.XGBClassifier(), X_test, Y_test, \n",
    "                  model_name = \"xg_boost_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
