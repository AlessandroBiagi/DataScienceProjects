{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hotel_bookings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_csv(df):\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    \n",
    "    if not os.path.exists('value_counts_csv'):\n",
    "        os.makedirs('value_counts_csv')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        value_counts = pd.DataFrame(df[col].value_counts(dropna = False, ascending = False))\n",
    "        value_counts['Percentage'] = value_counts.iloc[:,0]/sum(value_counts.iloc[:,0])\n",
    "        \n",
    "        value_counts.reset_index(drop = False, inplace = True)\n",
    "        value_counts.rename(columns = {'index': col, col: 'Count'}, inplace = True)\n",
    "        \n",
    "        value_counts.to_csv('./value_counts_csv/'+col+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nulls(df):\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    \n",
    "    if not os.path.exists('./value_counts_csv/Nulls_folder'):\n",
    "        os.makedirs('./value_counts_csv/Nulls_folder')\n",
    "    \n",
    "    nulls = pd.DataFrame(df.isna().sum())\n",
    "    nulls.reset_index(drop = False, inplace = True)\n",
    "    nulls.rename(columns = {'index': 'Column_Name', nulls.columns[1]:'Count'}, inplace = True)\n",
    "    \n",
    "    nulls['Percentage'] = nulls['Count']/df.shape[0]\n",
    "        \n",
    "    nulls.to_csv('./value_counts_csv/Nulls_folder/Nulls.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_boxplot(df):\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    \n",
    "    if not os.path.exists('plots/distribution'):\n",
    "        os.makedirs('plots/distribution')\n",
    "        \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.object:\n",
    "            plt.figure(col)\n",
    "            plt.hist(df[col].dropna())\n",
    "            plt.savefig('plots/distribution/' + col)\n",
    "            plt.close(col)\n",
    "        else:\n",
    "            fig, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "            plt.sca(ax[0])\n",
    "            plt.hist(df[col].dropna())\n",
    "                \n",
    "            plt.sca(ax[1])\n",
    "            df.boxplot(column=col)\n",
    "                \n",
    "            fig.savefig('plots/distribution/' + col)\n",
    "            plt.close(fig)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts_csv(df)\n",
    "count_nulls(df)\n",
    "hist_boxplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python setup.py install--user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()\n",
    "df_model = df_model.select_dtypes(exclude=['object'])\n",
    "df_model = pd.get_dummies(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119390, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.shape\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop('is_canceled', axis = 1)\n",
    "y = df_model['is_canceled']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75166\n",
       "1    44224\n",
       "Name: is_canceled, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30378234 0.69621766]\n",
      " [0.8485303  0.15146971]\n",
      " [0.63967097 0.360329  ]\n",
      " ...\n",
      " [0.8928962  0.10710382]\n",
      " [0.6548712  0.34512874]\n",
      " [0.7434501  0.25654984]]\n",
      "[1 0 0 ... 0 0 0]\n",
      "Precision = 0.7651682925149316\n",
      "Recall = 0.7372718628401349\n",
      "Accuracy = 0.7740179244492839\n"
     ]
    }
   ],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=Y_test)\n",
    "\n",
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 2} \n",
    "\n",
    "steps = 20  # The number of training iterations\n",
    "\n",
    "model = xgb.train(param, D_train, steps)\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "print(preds)\n",
    "\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print(best_preds)\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "     \"eta\"    : [0.20, 0.30] ,\n",
    "     \"max_depth\"        : [ 3, 6],\n",
    "     \"gamma\"            : [ 0.1, 0.2]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(xgb_clf,\n",
    "                    parameters,\n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3)\n",
    "\n",
    "model = grid.fit(X_train, Y_train)\n",
    "#predictions = model.predict(X_test)\n",
    "\n",
    "#model.dump_model('dump.raw.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eta=0.2, gamma=0.1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.448651451896503 {'eta': 0.2, 'gamma': 0.1, 'max_depth': 3}\n",
      "-0.4030927727304741 {'eta': 0.2, 'gamma': 0.1, 'max_depth': 6}\n",
      "-0.44865160945180954 {'eta': 0.2, 'gamma': 0.2, 'max_depth': 3}\n",
      "-0.4037234858139123 {'eta': 0.2, 'gamma': 0.2, 'max_depth': 6}\n",
      "-0.448651451896503 {'eta': 0.3, 'gamma': 0.1, 'max_depth': 3}\n",
      "-0.4030927727304741 {'eta': 0.3, 'gamma': 0.1, 'max_depth': 6}\n",
      "-0.44865160945180954 {'eta': 0.3, 'gamma': 0.2, 'max_depth': 3}\n",
      "-0.4037234858139123 {'eta': 0.3, 'gamma': 0.2, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "model.best_params_\n",
    "model.best_estimator_\n",
    "cvres = model.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(train['QuoteConversion_Flag'], n_folds=5, shuffle=True), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clf.fit(train[features], train[\"QuoteConversion_Flag\"])\n",
    "\n",
    "#trust your CV!\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "test_probs = clf.predict_proba(test[features])[:,1]\n",
    "\n",
    "sample = pd.read_csv('../input/sample_submission.csv')\n",
    "sample.QuoteConversion_Flag = test_probs\n",
    "sample.to_csv(\"xgboost_best_parameter_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_gridCV(X_train, y_train, clf, \n",
    "                      X_test = None, y_test = None, cv = 3, scoring = 'accuracy', params = {}, model_name = \"model\"):\n",
    "    \n",
    "    grid = GridSearchCV(clf, params, cv = cv, scoring = scoring, refit = True)\n",
    "    \n",
    "    model = grid.fit(X_train, y_train)\n",
    "    print(\"The best parameters of grid are: \", model.best_params_, \n",
    "          \"\\nThe best estimator is: \", model.best_estimator_)\n",
    "    \n",
    "    if not os.path.exists('Models/CV_results'):\n",
    "        os.makedirs('Models/CV_results')\n",
    "    \n",
    "    cvres = model.cv_results_\n",
    "    \n",
    "    if params != {}:    \n",
    "        dataframe = pd.DataFrame(cvres[\"params\"])\n",
    "        dataframe.insert(0, \"mean_test_score\", cvres[\"mean_test_score\"])\n",
    "                        \n",
    "    else: \n",
    "        dataframe = pd.DataFrame({\"mean_test_score\":cvres[\"mean_test_score\"]})\n",
    "            \n",
    "    dataframe.to_csv(\"./Models/CV_results/CV_results_\"+model_name+\".csv\", index = False) \n",
    "    \n",
    "    if X_test is not None:\n",
    "        results = model.predict(X_test)\n",
    "    \n",
    "        if y_test is not None:\n",
    "            print(\"Precision = {}\".format(precision_score(y_test, results, average='macro')))\n",
    "            print(\"Recall = {}\".format(recall_score(y_test, results, average='macro')))\n",
    "            print(\"Accuracy = {}\".format(accuracy_score(y_test, results)))\n",
    "            \n",
    "    return(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of grid are:  {} \n",
      "The best estimator is:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Precision = 0.7863874380590321\n",
      "Recall = 0.7546231566520929\n",
      "Accuracy = 0.7921098919507497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None, param_grid={},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_gridCV(X_train, Y_train, xgb.XGBClassifier(), X_test, Y_test, \n",
    "                  model_name = \"xg_boost_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
